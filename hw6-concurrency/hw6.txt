PART 1: No Concurrency
1.    out:    USER         PID    PPID NLWP     LWP S CMD
              abrigham 1002769 1002375    1 1002769 S echoserveri
2.    There is 1 process and 1 thread running.  This is because no concurrency is happening, so there aren't any threads, they are all running on the same one.  So only the data sent from window 1 gets sent through, since that's the connection made.  The data from 2 and 3 doesn't get received yet since only 1 thread and process is running.
3.    The next nc process I started (window 2) was able to connect to the server and send off the bytes that I entered earlier.  They couldn't get sent off initially because the server was connected to the client in window 1, and the server only had the 1 thread.  So once that client connection stopped, the server could then go to window 2 (the next client making a request to the server) and receive its data.

PART 2: Process-based Concurrency
4.    out:    USER         PID    PPID NLWP     LWP S CMD
              abrigham 1005562 1002375    1 1005562 S echoserverp
              abrigham 1005605 1005562    1 1005605 S echoserverp
              abrigham 1005625 1005562    1 1005625 S echoserverp
              abrigham 1005644 1005562    1 1005644 S echoserverp
5.    For process-based, there are 4 separate processes running, each on their own thread.  It's clear looking at the PIDs and LWPs since they're all different.  In this process-based version, it handles client connections as different processes, which allows them all to concurrently send data to the server.

PART 3: Simple Thread-based Concurrency
6.    out:    USER         PID    PPID NLWP     LWP S CMD
              abrigham 1007040 1002375    4 1007040 S echoservert
              abrigham 1007040 1002375    4 1007088 S echoservert
              abrigham 1007040 1002375    4 1007208 S echoservert
              abrigham 1007040 1002375    4 1007261 S echoservert
7.    For simple thread-based, there is only 1 process running, and on that process there are 4 individual threads.  This is because they all have the same PID (meaning all 1 process) yet they have different LWPs.  In this thread-based version, it handles client connections all in the same process but on different threads.  Since they're all on different threads, they're able to still concurrently send data to the server.

PART 4: Threadpool-based Concurrency
8.    out:    USER         PID    PPID NLWP     LWP S CMD
              abrigham 1008413 1002375   11 1008413 S echoservert_pre
              abrigham 1008413 1002375   11 1008414 S echoservert_pre
              abrigham 1008413 1002375   11 1008415 S echoservert_pre
              abrigham 1008413 1002375   11 1008416 S echoservert_pre
              abrigham 1008413 1002375   11 1008417 S echoservert_pre
              abrigham 1008413 1002375   11 1008418 S echoservert_pre
              abrigham 1008413 1002375   11 1008419 S echoservert_pre
              abrigham 1008413 1002375   11 1008420 S echoservert_pre
              abrigham 1008413 1002375   11 1008421 S echoservert_pre
              abrigham 1008413 1002375   11 1008422 S echoservert_pre
              abrigham 1008413 1002375   11 1008423 S echoservert_pre
9.    This time there still is 1 process (all have the same PID) and on that process there are separate threads (11 this time).  With simple thread-based, it creates a new thread every time a new task needs to be executed, but with threadpool there's a set/max number of threads that just be used whenever new tasks need completed.  If there's too many tasks for the number of threads, then it will wait to finish current tasks until running those pending.

PART 5: Concurrency Review

10.   echoserverp (Process-based Concurrency)
      Pro:    Easier to code up.  Also since each thread is on its own process, the threads can easily be run on different cores of the CPU.
      Con:    Heavier on system resources than threads because it has to make a new process and thread for every single task that needs to be run.

11.   echoservert (Thread-based Concurrency)
      Pro:    Client tasks will always be able to be run on the server because you can just make a new thread for it (those tasks will never have to wait in order to be run).  Harder to code, but generally a better solution than process-based.
      Con:    If there are too many threads running, it will bog down the system resources and the computer will slow down (more and more threads can be created to meet the number of tasks)

12.   echoservert_pre (Threadpool-based Concurrency)
      Pro:    You can ensure that your server computer won't slow down because there's a cap to how many threads are made (fixed number), so if you receive too many tasks to be run (so many that it would slow down your machine), it will only take those it can handle, and wait to process the rest.
      Con:    Because there's a fixed number of threads that can be made, if many tasks are trying to be run on the server, some tasks will inevitably have to wait until one of the threads is available before it can be run.

13.   The statements in the main function within the while(1) loop that make the accept() call and then call sbuf_insert() are the producer's role.  There are 1 producer threads.  It's keeping all the consumers in sync, running when they need to.

14.   The statements in the thread function within the while(1) loop that make the sbuf_remove() call are the consumer's role.  There are 10 consumer threads (10 was a fixed number), and in line 40 it loops through 10 times making consumer threads.

15.   It will just keep waiting for an available slot (when slots gets a value bigger than 0).  Then it will decrement slots and run its code.

16.   The producer will execute line 33, which will call V() or sem_post(), incrementing the number of items.  Once the number of items is 1 (non-zero), the sleeping consumer thread will wake up, decrements items, and keep running the code in sbuf_remove().